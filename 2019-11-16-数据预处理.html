<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5"><title>数据预处理 | BraveY</title><meta name="description" content="数据预处理"><meta name="keywords" content="课程,国科大,降维,相关性分析"><meta name="author" content="BraveY"><meta name="copyright" content="BraveY"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/favicon.png"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="https://fonts.googleapis.com" crossorigin><link rel="preconnect" href="//busuanzi.ibruce.info"><meta name="baidu-site-verification" content="8XIUcPkbzm"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="数据预处理"><meta name="twitter:description" content="数据预处理"><meta name="twitter:image" content="https://images.pexels.com/photos/1005763/pexels-photo-1005763.jpeg?auto=compress&amp;cs=tinysrgb&amp;dpr=1&amp;w=500"><meta property="og:type" content="article"><meta property="og:title" content="数据预处理"><meta property="og:url" content="https://bravey.github.io/2019-11-16-数据预处理"><meta property="og:site_name" content="BraveY"><meta property="og:description" content="数据预处理"><meta property="og:image" content="https://images.pexels.com/photos/1005763/pexels-photo-1005763.jpeg?auto=compress&amp;cs=tinysrgb&amp;dpr=1&amp;w=500"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script>const autoChangeMode = 'false'
var t = Cookies.get("theme");
if (autoChangeMode == '1'){
const isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches
const isLightMode = window.matchMedia("(prefers-color-scheme: light)").matches
const isNotSpecified = window.matchMedia("(prefers-color-scheme: no-preference)").matches
const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

if (t === undefined){
  if (isLightMode) activateLightMode()
  else if (isDarkMode) activateDarkMode()
  else if (isNotSpecified || hasNoSupport){
    console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
    now = new Date();
    hour = now.getHours();
    isNight = hour < 6 || hour >= 18
    isNight ? activateDarkMode() : activateLightMode()
}
} else if (t == 'light') activateLightMode()
else activateDarkMode()


} else if (autoChangeMode == '2'){
  now = new Date();
  hour = now.getHours();
  isNight = hour < 6 || hour >= 18
  if(t === undefined) isNight? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode() 
} else {
  if ( t == 'dark' ) activateDarkMode()
  else if ( t == 'light') activateLightMode()
}

function activateDarkMode(){
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null){
    document.querySelector('meta[name="theme-color"]').setAttribute('content','#000')
  }
}
function activateLightMode(){
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null){
  document.querySelector('meta[name="theme-color"]').setAttribute('content','#fff')
  }
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="canonical" href="https://bravey.github.io/2019-11-16-数据预处理"><link rel="prev" title="分类与预测" href="https://bravey.github.io/2019-11-17-分类与预测.html"><link rel="next" title="数据仓库" href="https://bravey.github.io/2019-11-15-数据仓库.html"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容:${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://xxx/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    title: 'Snackbar.bookmark.title',
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: true,
  copyright: undefined,
  ClickShowText: {"text":"富强,民主,文明,和谐,自由,平等,公正,法治,爱国,敬业,诚信,友善","fontSize":"15px"},
  medium_zoom: false,
  fancybox: true,
  Snackbar: undefined,
  baiduPush: true,
  isHome: false,
  isPost: true
  
}</script></head><body><canvas class="fireworks"></canvas><header> <div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">BraveY</a></span><span class="toggle-menu pull_right close"><a class="site-page"><i class="fa fa-bars fa-fw" aria-hidden="true"></i></a></span><span class="pull_right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div></div></span><span class="pull_right" id="search_button"><a class="site-page social-icon search"><i class="fa fa-search fa-fw"></i><span> 搜索</span></a></span></div></header><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/avatar3.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">56</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">88</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">14</div></a></div></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div></div></div><div id="mobile-sidebar-toc"><div class="toc_mobile_headline">目录</div><div class="sidebar-toc__content"><ol class="toc_mobile_items"><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#数据预处理"><span class="toc_mobile_items-number">1.</span> <span class="toc_mobile_items-text">数据预处理</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#为什么数据预处理"><span class="toc_mobile_items-number">1.1.</span> <span class="toc_mobile_items-text">为什么数据预处理</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#数据描述"><span class="toc_mobile_items-number">1.2.</span> <span class="toc_mobile_items-text">数据描述</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#中心趋势度量"><span class="toc_mobile_items-number">1.2.1.</span> <span class="toc_mobile_items-text">中心趋势度量</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#平均值-mean"><span class="toc_mobile_items-number">1.2.1.1.</span> <span class="toc_mobile_items-text">平均值 mean</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#中位数-median"><span class="toc_mobile_items-number">1.2.1.2.</span> <span class="toc_mobile_items-text">中位数 median</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#众数-mode"><span class="toc_mobile_items-number">1.2.1.3.</span> <span class="toc_mobile_items-text">众数 mode</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#中列数-midrange"><span class="toc_mobile_items-number">1.2.1.4.</span> <span class="toc_mobile_items-text">中列数 midrange</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#对称与倾斜"><span class="toc_mobile_items-number">1.2.1.5.</span> <span class="toc_mobile_items-text">对称与倾斜</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#数据散布度量"><span class="toc_mobile_items-number">1.2.2.</span> <span class="toc_mobile_items-text">数据散布度量</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#极差、四分位数和四分位数极差"><span class="toc_mobile_items-number">1.2.2.1.</span> <span class="toc_mobile_items-text">极差、四分位数和四分位数极差</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#五数概括、盒图与离群点"><span class="toc_mobile_items-number">1.2.2.2.</span> <span class="toc_mobile_items-text">五数概括、盒图与离群点</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#方差、标准差"><span class="toc_mobile_items-number">1.2.2.3.</span> <span class="toc_mobile_items-text">方差、标准差</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#数据描述的图形表示"><span class="toc_mobile_items-number">1.2.3.</span> <span class="toc_mobile_items-text">数据描述的图形表示</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#直方图"><span class="toc_mobile_items-number">1.2.3.1.</span> <span class="toc_mobile_items-text">直方图</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#分位数图"><span class="toc_mobile_items-number">1.2.3.2.</span> <span class="toc_mobile_items-text">分位数图</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#分位数-分位数图"><span class="toc_mobile_items-number">1.2.3.3.</span> <span class="toc_mobile_items-text">分位数-分位数图</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#散点图"><span class="toc_mobile_items-number">1.2.3.4.</span> <span class="toc_mobile_items-text">散点图</span></a></li></ol></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#数据清洗"><span class="toc_mobile_items-number">1.3.</span> <span class="toc_mobile_items-text">数据清洗</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#缺失值"><span class="toc_mobile_items-number">1.3.0.1.</span> <span class="toc_mobile_items-text">缺失值</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#噪声数据"><span class="toc_mobile_items-number">1.3.0.2.</span> <span class="toc_mobile_items-text">噪声数据</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-5"><a class="toc_mobile_items-link" href="#分箱"><span class="toc_mobile_items-number">1.3.0.2.1.</span> <span class="toc_mobile_items-text">分箱</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-5"><a class="toc_mobile_items-link" href="#回归"><span class="toc_mobile_items-number">1.3.0.2.2.</span> <span class="toc_mobile_items-text">回归</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-5"><a class="toc_mobile_items-link" href="#聚类"><span class="toc_mobile_items-number">1.3.0.2.3.</span> <span class="toc_mobile_items-text">聚类</span></a></li></ol></li></ol></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#数据转换"><span class="toc_mobile_items-number">1.4.</span> <span class="toc_mobile_items-text">数据转换</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#归一化-规范化"><span class="toc_mobile_items-number">1.4.1.</span> <span class="toc_mobile_items-text">归一化/规范化</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#最大-最小归一化"><span class="toc_mobile_items-number">1.4.1.1.</span> <span class="toc_mobile_items-text">最大-最小归一化</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#z-score归一化"><span class="toc_mobile_items-number">1.4.1.2.</span> <span class="toc_mobile_items-text">z-score归一化</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#小数定标归一化"><span class="toc_mobile_items-number">1.4.1.3.</span> <span class="toc_mobile_items-text">小数定标归一化</span></a></li></ol></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#冗余与相关性分析"><span class="toc_mobile_items-number">1.5.</span> <span class="toc_mobile_items-text">冗余与相关性分析</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#数值数据的相关系数"><span class="toc_mobile_items-number">1.5.1.</span> <span class="toc_mobile_items-text">数值数据的相关系数</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#分类数据的-chi-2-相关检验"><span class="toc_mobile_items-number">1.5.2.</span> <span class="toc_mobile_items-text">分类数据的$\chi^2$相关检验</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#数据归约"><span class="toc_mobile_items-number">1.6.</span> <span class="toc_mobile_items-text">数据归约</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#维规约"><span class="toc_mobile_items-number">1.6.1.</span> <span class="toc_mobile_items-text">维规约</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#小波变换"><span class="toc_mobile_items-number">1.6.1.1.</span> <span class="toc_mobile_items-text">小波变换</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#主成分分析"><span class="toc_mobile_items-number">1.6.1.2.</span> <span class="toc_mobile_items-text">主成分分析</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#属性-特征子集选择"><span class="toc_mobile_items-number">1.6.1.3.</span> <span class="toc_mobile_items-text">属性/特征子集选择</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#数量规约"><span class="toc_mobile_items-number">1.6.2.</span> <span class="toc_mobile_items-text">数量规约</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#数据立方体集成"><span class="toc_mobile_items-number">1.6.2.1.</span> <span class="toc_mobile_items-text">数据立方体集成</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#回归-1"><span class="toc_mobile_items-number">1.6.2.2.</span> <span class="toc_mobile_items-text">回归</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#直方图-1"><span class="toc_mobile_items-number">1.6.2.3.</span> <span class="toc_mobile_items-text">直方图</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#聚类-1"><span class="toc_mobile_items-number">1.6.2.4.</span> <span class="toc_mobile_items-text">聚类</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#抽样"><span class="toc_mobile_items-number">1.6.2.5.</span> <span class="toc_mobile_items-text">抽样</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#数据压缩"><span class="toc_mobile_items-number">1.6.3.</span> <span class="toc_mobile_items-text">数据压缩</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#数据离散和概念分层"><span class="toc_mobile_items-number">1.6.4.</span> <span class="toc_mobile_items-text">数据离散和概念分层</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#参考"><span class="toc_mobile_items-number">1.7.</span> <span class="toc_mobile_items-text">参考</span></a></li></ol></li></ol></div></div></div><div id="body-wrap"><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true">     </i><div class="auto_open" id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#数据预处理"><span class="toc-number">1.</span> <span class="toc-text">数据预处理</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#为什么数据预处理"><span class="toc-number">1.1.</span> <span class="toc-text">为什么数据预处理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#数据描述"><span class="toc-number">1.2.</span> <span class="toc-text">数据描述</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#中心趋势度量"><span class="toc-number">1.2.1.</span> <span class="toc-text">中心趋势度量</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#平均值-mean"><span class="toc-number">1.2.1.1.</span> <span class="toc-text">平均值 mean</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#中位数-median"><span class="toc-number">1.2.1.2.</span> <span class="toc-text">中位数 median</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#众数-mode"><span class="toc-number">1.2.1.3.</span> <span class="toc-text">众数 mode</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#中列数-midrange"><span class="toc-number">1.2.1.4.</span> <span class="toc-text">中列数 midrange</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#对称与倾斜"><span class="toc-number">1.2.1.5.</span> <span class="toc-text">对称与倾斜</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#数据散布度量"><span class="toc-number">1.2.2.</span> <span class="toc-text">数据散布度量</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#极差、四分位数和四分位数极差"><span class="toc-number">1.2.2.1.</span> <span class="toc-text">极差、四分位数和四分位数极差</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#五数概括、盒图与离群点"><span class="toc-number">1.2.2.2.</span> <span class="toc-text">五数概括、盒图与离群点</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#方差、标准差"><span class="toc-number">1.2.2.3.</span> <span class="toc-text">方差、标准差</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#数据描述的图形表示"><span class="toc-number">1.2.3.</span> <span class="toc-text">数据描述的图形表示</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#直方图"><span class="toc-number">1.2.3.1.</span> <span class="toc-text">直方图</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#分位数图"><span class="toc-number">1.2.3.2.</span> <span class="toc-text">分位数图</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#分位数-分位数图"><span class="toc-number">1.2.3.3.</span> <span class="toc-text">分位数-分位数图</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#散点图"><span class="toc-number">1.2.3.4.</span> <span class="toc-text">散点图</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#数据清洗"><span class="toc-number">1.3.</span> <span class="toc-text">数据清洗</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#缺失值"><span class="toc-number">1.3.0.1.</span> <span class="toc-text">缺失值</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#噪声数据"><span class="toc-number">1.3.0.2.</span> <span class="toc-text">噪声数据</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#分箱"><span class="toc-number">1.3.0.2.1.</span> <span class="toc-text">分箱</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#回归"><span class="toc-number">1.3.0.2.2.</span> <span class="toc-text">回归</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#聚类"><span class="toc-number">1.3.0.2.3.</span> <span class="toc-text">聚类</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#数据转换"><span class="toc-number">1.4.</span> <span class="toc-text">数据转换</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#归一化-规范化"><span class="toc-number">1.4.1.</span> <span class="toc-text">归一化/规范化</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#最大-最小归一化"><span class="toc-number">1.4.1.1.</span> <span class="toc-text">最大-最小归一化</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#z-score归一化"><span class="toc-number">1.4.1.2.</span> <span class="toc-text">z-score归一化</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#小数定标归一化"><span class="toc-number">1.4.1.3.</span> <span class="toc-text">小数定标归一化</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#冗余与相关性分析"><span class="toc-number">1.5.</span> <span class="toc-text">冗余与相关性分析</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#数值数据的相关系数"><span class="toc-number">1.5.1.</span> <span class="toc-text">数值数据的相关系数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#分类数据的-chi-2-相关检验"><span class="toc-number">1.5.2.</span> <span class="toc-text">分类数据的$\chi^2$相关检验</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#数据归约"><span class="toc-number">1.6.</span> <span class="toc-text">数据归约</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#维规约"><span class="toc-number">1.6.1.</span> <span class="toc-text">维规约</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#小波变换"><span class="toc-number">1.6.1.1.</span> <span class="toc-text">小波变换</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#主成分分析"><span class="toc-number">1.6.1.2.</span> <span class="toc-text">主成分分析</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#属性-特征子集选择"><span class="toc-number">1.6.1.3.</span> <span class="toc-text">属性/特征子集选择</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#数量规约"><span class="toc-number">1.6.2.</span> <span class="toc-text">数量规约</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#数据立方体集成"><span class="toc-number">1.6.2.1.</span> <span class="toc-text">数据立方体集成</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#回归-1"><span class="toc-number">1.6.2.2.</span> <span class="toc-text">回归</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#直方图-1"><span class="toc-number">1.6.2.3.</span> <span class="toc-text">直方图</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#聚类-1"><span class="toc-number">1.6.2.4.</span> <span class="toc-text">聚类</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#抽样"><span class="toc-number">1.6.2.5.</span> <span class="toc-text">抽样</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#数据压缩"><span class="toc-number">1.6.3.</span> <span class="toc-text">数据压缩</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#数据离散和概念分层"><span class="toc-number">1.6.4.</span> <span class="toc-text">数据离散和概念分层</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#参考"><span class="toc-number">1.7.</span> <span class="toc-text">参考</span></a></li></ol></li></ol></div></div></div><main id="content-outer"><div id="top-container" style="background-image: url(https://images.pexels.com/photos/1005763/pexels-photo-1005763.jpeg?auto=compress&amp;cs=tinysrgb&amp;dpr=1&amp;w=500)"><div id="post-info"><div id="post-title"><div class="posttitle">数据预处理</div></div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 发表于 2019-11-16<span class="post-meta__separator">|</span><i class="fa fa-history fa-fw" aria-hidden="true"></i> 更新于 2020-03-04</time><span class="post-meta__separator">|</span><span><i class="fa fa-inbox post-meta__icon fa-fw" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/数据挖掘/">数据挖掘</a></span><div class="post-meta-wordcount"><div class="post-meta-pv-cv"><span><i class="fa fa-eye post-meta__icon fa-fw" aria-hidden="true"> </i>阅读量:</span><span id="busuanzi_value_page_pv"></span></div></div></div></div></div><div class="layout layout_post" id="content-inner">   <article id="post"><div class="article-container" id="post-content"><h1 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h1><h2 id="为什么数据预处理"><a href="#为什么数据预处理" class="headerlink" title="为什么数据预处理"></a>为什么数据预处理</h2><p>原始数据可能掺杂着噪音、空值或者不正确、不一致、充满冗余值等。没有高质量的数据，很难挖掘出高质量的规则，因此需要数据预处理。数据预处理主要有：数据清洗、数据集成、数据归约、数据离散等几个任务。</p>
<a id="more"></a>
<h2 id="数据描述"><a href="#数据描述" class="headerlink" title="数据描述"></a>数据描述</h2><p>得到一份数据后，需要先对数据进行一个大概的认识，主要从中心趋势和发散特征两方面统计进行描述。</p>
<h3 id="中心趋势度量"><a href="#中心趋势度量" class="headerlink" title="中心趋势度量"></a>中心趋势度量</h3><h4 id="平均值-mean"><a href="#平均值-mean" class="headerlink" title="平均值 mean"></a>平均值 mean</h4><p>均值又分为：</p>
<ul>
<li><p>算术均值</p>
<p> $\bar x=\frac{1}{n}\sum_{i=1}^{n}x_i$</p>
</li>
<li><p>加权均值</p>
<p>$\bar x= \frac{\sum_{i=1}^{n}w_ix_i}{\sum_{i=1}^{n}w_i}$</p>
</li>
<li><p>截尾均值 Trimmed mean</p>
<p>均值对极端数据比如离群点很敏感。因此截取高低两端的一部分数据后再计算均值，但是截去的部分不能太多不超过$20\%$</p>
</li>
</ul>
<h4 id="中位数-median"><a href="#中位数-median" class="headerlink" title="中位数 median"></a>中位数 median</h4><p>对于倾斜（非对称）数据，数据中心的更好度量是中位数。</p>
<p>假定数据有序，则当n为奇数时中位数是中间的值，当n为偶数的时候，中位数不唯一，可以是中间两个值和之间的任意值。如果属性是数值属性，那么一般约定取中间两个值的平均值。</p>
<h4 id="众数-mode"><a href="#众数-mode" class="headerlink" title="众数 mode"></a>众数 mode</h4><p>另一种中心趋势的度量方法，众数是集合中出现最频繁的值。数据可能会有多个众数，如果最高频的值有多个的时候。如果每个数据值近出现一次，是没有众数的。</p>
<p>有一个、两个、三个众数的分别称为：单峰的(unimodal)、双峰的（bimodal）和三峰的（trimodal）</p>
<h4 id="中列数-midrange"><a href="#中列数-midrange" class="headerlink" title="中列数 midrange"></a>中列数 midrange</h4><p>中列数是数据集的最大和最小值的平均值。</p>
<h4 id="对称与倾斜"><a href="#对称与倾斜" class="headerlink" title="对称与倾斜"></a>对称与倾斜</h4><p>完全对称的数据分布的单峰频率曲线中，均值、中位数和众数三者是相同的中心值。</p>
<p>不对称的情况分为：</p>
<ul>
<li>正倾斜：众数小于中位数</li>
<li>负倾斜：众数大于中位数</li>
</ul>
<p>如下所示,最上方是对称的，左下是正倾斜的，右下是负倾斜的。</p>
<p><a href="https://res.cloudinary.com/bravey/image/upload/v1573992640/blog/Data%20Mining/symmetric_skewed.jpg" data-fancybox="group" data-caption="" class="fancybox"><img src="https://res.cloudinary.com/bravey/image/upload/v1573992640/blog/Data%20Mining/symmetric_skewed.jpg" alt="" title=""></a></p>
<h3 id="数据散布度量"><a href="#数据散布度量" class="headerlink" title="数据散布度量"></a>数据散布度量</h3><h4 id="极差、四分位数和四分位数极差"><a href="#极差、四分位数和四分位数极差" class="headerlink" title="极差、四分位数和四分位数极差"></a>极差、四分位数和四分位数极差</h4><p><strong>极差（range）</strong>：最大值与最小值之差。</p>
<p>有序数据值下的数据集合的第k 个百分位数是具有如下性质的值x：数据项的百分之k 在x 上或低于x。在中位数M上或低于M 的值对应于第50 个百分位数。</p>
<p><strong>四分位数</strong>将数据分为4段总共有3个四分位数，Q1是第25个百分位数，Q2即是Median是第50个百分位数，Q3是第75个百分位数。</p>
<p>100-分位数通常称为百分位数，它们把数据分成100个大小相等的连贯集。中位数、四分位数和百分位数是使用最广泛的分位数。</p>
<p>第一个和第三个四分位数之间的距离是分布的一种简单度量，它给出被数据的中间一半<br>所覆盖的范围。该距离称为中间<strong>四分位数极差（IQR）</strong>：$IQR=Q_3-Q_1$</p>
<h4 id="五数概括、盒图与离群点"><a href="#五数概括、盒图与离群点" class="headerlink" title="五数概括、盒图与离群点"></a>五数概括、盒图与离群点</h4><p><strong>离群点(Outlier)</strong>：与$Q_1$或者$Q_3$这两个分位数的值超过$1.5IQR$</p>
<p>五数概括使用最小值、$Q_1$ 、中位数、$Q_3$、最大值来概述数据的中心与散布。</p>
<p>可以使用盒图来体现五数概括 。</p>
<ul>
<li>盒的端点在四分位数上，使得盒的长度是中间四分位数区间IQR</li>
<li>中位数用盒内的线标记</li>
<li>盒外的两条线（称作胡须）延伸到最小（Minimum）和最大（Maximum）观测值。如果最大最小值超过$1.5IQR$，那么只延伸到这个部分。</li>
</ul>
<p><a href="https://res.cloudinary.com/bravey/image/upload/v1573992640/blog/Data%20Mining/box_plot.jpg" data-fancybox="group" data-caption="" class="fancybox"><img src="https://res.cloudinary.com/bravey/image/upload/v1573992640/blog/Data%20Mining/box_plot.jpg" alt="" title=""></a></p>
<p>如上图所示，最大值超过了$1.5IQR$所以只延伸到了$1.5IQR$，而超过$1.5IQR$部分的被标记为离群点。</p>
<h4 id="方差、标准差"><a href="#方差、标准差" class="headerlink" title="方差、标准差"></a>方差、标准差</h4><p>方差Variance与标准差Standard deviation指出数据分布的散布程度。</p>
<p>总体方差的计算：$\sigma^2=\frac{1}{n}\sum_{i=1}^{n}(x_i-\mu)^2={\frac{1}{n}\sum_{i=1}^{n}x_i^2}-{\mu}^2$</p>
<p>样本方差的计算：$s^2=\frac{1}{n-1}\sum_{i=1}^{n}(x_i-\bar x)^2={\frac{1}{n-1}（\sum_{i=1}^{n}x_i^2}-\frac{1}{n}\sum_{i=1}^{n}x_i^2）$</p>
<p>$\mu$是总体数据的平均值，而$\bar x$是总体数据中的一部分样本的均值，可以用样本的均值来估计总体的均值。样本方差是无偏估计的，<a href="https://www.zhihu.com/question/20099757" target="_blank" rel="noopener">样本方差与总体方差的差别</a></p>
<p>标准差是方差的平方根，就是$\sigma$或者s。它的性质是：</p>
<ul>
<li>$\sigma$<strong>度量关于平均值的发散</strong>，仅当选择平均值作为中心度量时使用。</li>
<li>仅当不存在发散时，即当所有的观测值都相同时，$\sigma=0$。否则，$\sigma&gt;0$。</li>
</ul>
<h3 id="数据描述的图形表示"><a href="#数据描述的图形表示" class="headerlink" title="数据描述的图形表示"></a>数据描述的图形表示</h3><h4 id="直方图"><a href="#直方图" class="headerlink" title="直方图"></a>直方图</h4><p>直方图Histogram 或者频率直方图Frequency histograms 针对单变量，对于比较单变量观测组，它可能不如分位数图、q-q 图和盒图方法有效。</p>
<p><a href="https://res.cloudinary.com/bravey/image/upload/v1573992639/blog/Data%20Mining/histogram.jpg" data-fancybox="group" data-caption="" class="fancybox"><img src="https://res.cloudinary.com/bravey/image/upload/v1573992639/blog/Data%20Mining/histogram.jpg" alt="" title=""></a></p>
<h4 id="分位数图"><a href="#分位数图" class="headerlink" title="分位数图"></a>分位数图</h4><p>分位数图Quantile Plot每个观测值$x_i$与一个百分数$f_i$配对，指出大约$f_i \times 100\%$的数据小于值$x_i$，“大约”是因为可能没有一个精确的小数值$f_i$，使得数据的$f_i\%$小于或等于$x_i$。0.25 分位数对应于Q1，0.50 分位数对应于中位数，而0.75 分位数对应于Q3。</p>
<p>$f_i$的定义：$f_i=\frac{i-0.5}{N}$这些数由$\frac{1}{2N}$（稍大于0）到$1-\frac{1}{2N}$（稍小于1），以相同的步长1/n 递增。</p>
<p><a href="https://res.cloudinary.com/bravey/image/upload/v1573992640/blog/Data%20Mining/Quantile_Plot.jpg" data-fancybox="group" data-caption="" class="fancybox"><img src="https://res.cloudinary.com/bravey/image/upload/v1573992640/blog/Data%20Mining/Quantile_Plot.jpg" alt="" title=""></a></p>
<h4 id="分位数-分位数图"><a href="#分位数-分位数图" class="headerlink" title="分位数-分位数图"></a>分位数-分位数图</h4><p>分位数-分位数图Quantile-Quantile Plot，或q-q 图对着另一个的对应分位数，绘制一个单变量分布的分位数。它是一种强有力的直观表示工具，使得用户可以观察从一个分布到另一个是否有漂移。![]<a href="https://res.cloudinary.com/bravey/image/upload/v1573992640/blog/Data%20Mining/qq_plot.jpg" target="_blank" rel="noopener">https://res.cloudinary.com/bravey/image/upload/v1573992640/blog/Data%20Mining/qq_plot.jpg</a>)</p>
<p>部门1的分布相对于部门2有一个漂移，更趋向于部门2，说明部门2的单价趋向于比部门1高。</p>
<h4 id="散点图"><a href="#散点图" class="headerlink" title="散点图"></a>散点图</h4><p>散点图(scatter plot)是确定两个量化变量之间看上去是否有联系、模式或趋势的最有效的图形方法之一。</p>
<p>它观察的是<strong>双变量</strong>，可以观察点簇和离群点，或者考察相关性。正相关x随着y的增加而增加，负相关x随着y的增长而减少。</p>
<p><a href="https://res.cloudinary.com/bravey/image/upload/v1573992640/blog/Data%20Mining/scatter_plot.jpg" data-fancybox="group" data-caption="" class="fancybox"><img src="https://res.cloudinary.com/bravey/image/upload/v1573992640/blog/Data%20Mining/scatter_plot.jpg" alt="" title=""></a></p>
<h2 id="数据清洗"><a href="#数据清洗" class="headerlink" title="数据清洗"></a>数据清洗</h2><h4 id="缺失值"><a href="#缺失值" class="headerlink" title="缺失值"></a>缺失值</h4><ul>
<li>忽略元组</li>
<li>人工填写缺值</li>
<li>使用全局常量填充 ：比如Unknown </li>
<li>所有样本的中心值填充：均值或者中位数 均值要求数据对称分布，倾斜分布用中位数</li>
<li>给定元组的分类相同的样本的均值或者中位数</li>
<li>最可能的值：使用贝叶斯推理、回归、决策数等进行预测。 前面几种是有偏的，这种方法最常用。</li>
</ul>
<h4 id="噪声数据"><a href="#噪声数据" class="headerlink" title="噪声数据"></a>噪声数据</h4><h5 id="分箱"><a href="#分箱" class="headerlink" title="分箱"></a>分箱</h5><p>分箱方法通过考察“邻居”（即，周围的值）来平滑存储数据的值。存储的值被分布到一些“桶”或箱中。由于分箱方法导致值相邻，因此它进行局部平滑。</p>
<p>要求数据有序因此需要<strong>先进行排序</strong>，有三种方法：</p>
<ul>
<li><strong>箱均值光滑</strong>：箱中的每一个值被替换为箱中的均值</li>
<li><strong>箱中位数光滑：</strong>箱中的每一个值被替换为箱中的中位数</li>
<li><strong>箱边界光滑：</strong>边界为箱中的最大与最小值，每个值被替换为距离其最近的边界值。</li>
</ul>
<p>而箱子的分法有<strong>等频（等深）</strong>：每个箱子中的样本数目一样。<strong>等宽</strong>：按照取值范围将样本划分，每个箱子中的取值范围一致，比如样本数据取值为[0,10]那么可以按照等宽为2，把[0,2),[2,4)这样的取值范围来把样本划分到对应区间所在的范围中。</p>
<p><a href="https://res.cloudinary.com/bravey/image/upload/v1573992639/blog/Data%20Mining/bin.jpg" data-fancybox="group" data-caption="" class="fancybox"><img src="https://res.cloudinary.com/bravey/image/upload/v1573992639/blog/Data%20Mining/bin.jpg" alt="" title=""></a></p>
<h5 id="回归"><a href="#回归" class="headerlink" title="回归"></a>回归</h5><p>用函数拟合数据来光滑数据，将离拟合曲线远的数据标记为噪声数据。</p>
<h5 id="聚类"><a href="#聚类" class="headerlink" title="聚类"></a>聚类</h5><p>使用聚类分析后，检测出离群点，然后把离群点标记为噪声数据。</p>
<h2 id="数据转换"><a href="#数据转换" class="headerlink" title="数据转换"></a>数据转换</h2><h3 id="归一化-规范化"><a href="#归一化-规范化" class="headerlink" title="归一化/规范化"></a>归一化/规范化</h3><h4 id="最大-最小归一化"><a href="#最大-最小归一化" class="headerlink" title="最大-最小归一化"></a>最大-最小归一化</h4><p>对原始数据进行线性变换，映射到新的区间[new_min, new_max]中去。这种方法保持了原始数据之间的联系。</p>
<script type="math/tex; mode=display">
v_i'=\frac{v_i-min_A}{max_A-min_A}(new\_max_A-new\_min_A)</script><h4 id="z-score归一化"><a href="#z-score归一化" class="headerlink" title="z-score归一化"></a>z-score归一化</h4><p>新的值使用均值和标准差进行映射。$\bar A$和$\sigma_A$ 分别是样本的均值和他的标准差。</p>
<script type="math/tex; mode=display">
v_i'=\frac{v_i-\bar A}{\sigma_A}</script><h4 id="小数定标归一化"><a href="#小数定标归一化" class="headerlink" title="小数定标归一化"></a>小数定标归一化</h4><p>小数定标归一化 Normalization by decimal scaling。移动原来的小数点的位置来进行归一化。</p>
<script type="math/tex; mode=display">
v_i'=\dfrac{v_i}{10^j}</script><p>j是让$Max(|v_i’|&lt;1)$的最小整数，比如如果是254，那么j取3就可以让其为0.254小于1。</p>
<h2 id="冗余与相关性分析"><a href="#冗余与相关性分析" class="headerlink" title="冗余与相关性分析"></a>冗余与相关性分析</h2><p>一个属性可以由另外的属性导出，那么另外的属性就是冗余的。有些冗余可以通过<strong>相关性分析</strong>来检测</p>
<h3 id="数值数据的相关系数"><a href="#数值数据的相关系数" class="headerlink" title="数值数据的相关系数"></a>数值数据的相关系数</h3><p>相关系数Correlation coefficient也称作皮尔森积矩系数Pearson’s product moment coefficient估计两个属性A,B的相关度。</p>
<script type="math/tex; mode=display">
r_{A.B}=\dfrac{\sum_{i=1}^{n}(a_i-\bar A)(b_i-\bar B)}{(n-1)\sigma_A\sigma_B}=\dfrac{\sum_{i=1}^{n}(a_ib_i)-n\bar A\bar B}{(n-1)\sigma_A\sigma_b}</script><p>$-1\le r_{A,B}\le 1$ ,$r_{A,B}&gt;0$ A和B两个属性正相关，A的值随着B的值增长而增长。$r_{A,B}&lt;0$为负相关，A的值随着B的值增长而减少。该值越大，一个属性蕴涵另一个的可能性越大。因此，一个很大的值表明A（或B）可以作为冗余而被去掉。如果结果值等于0，则A 和B 是独立的，它们之间不相关。可以参见前述的散点图。</p>
<h3 id="分类数据的-chi-2-相关检验"><a href="#分类数据的-chi-2-相关检验" class="headerlink" title="分类数据的$\chi^2$相关检验"></a>分类数据的$\chi^2$相关检验</h3><p>分类数据Categorical Data中，两类数据可以通过$\chi^2$卡方检验来发现它们的相关性。计算公式为：</p>
<script type="math/tex; mode=display">
\begin{split}
&\chi^2=\sum_{i=1}^{c}\sum_{j=1}^{r}\dfrac{o_{ij}-e_{ij}}{e_{ij}}\\\\
&e_{ij}=\dfrac{count(A=a_i)\times count(B=b_j)}{n}
\end{split}</script><p>$o_{ij}$ 是联合事件$(A_i,B_j)$的观测频度也就是实际频数，而$e_{ij}$ 是$(A_i,B_j)$的期望值。n是总的数据样本数。使用相依表来表示数据。</p>
<p><a href="https://res.cloudinary.com/bravey/image/upload/v1573992639/blog/Data%20Mining/rely_table.jpg" data-fancybox="group" data-caption="" class="fancybox"><img src="https://res.cloudinary.com/bravey/image/upload/v1573992639/blog/Data%20Mining/rely_table.jpg" alt="" title=""></a></p>
<p>图中括号中的是每个单元的预测值。总共抽取1500个样本，因此n=1500。A类是否喜欢看小说有两类取值，B类性别也有两类取值，因此c=2，r=2。计算单元（男，小说）的预测值有：</p>
<script type="math/tex; mode=display">
e_{11}=\dfrac{count(男)\times count(小说)}{n}=\dfrac{300\times450}{1500}=90</script><p>其他几个单元的预测值都在括号中。因此可以计算出：</p>
<script type="math/tex; mode=display">
\chi^2=\dfrac{(250-90)^2}{90}+\dfrac{(50-210)^2}{210}+\dfrac{(200-360)^2}{360}+\dfrac{(1000-840)^2}{840}=507.93</script><p>对于这个2*2的表，自由度为（2-1)(2-1)=1。对于自由度1，在0.001的置信水平下，查表得到拒绝假设的值是10.828。算出来的值大与它，因此认为性别和爱看小说不是独立的，是强相关的。</p>
<h2 id="数据归约"><a href="#数据归约" class="headerlink" title="数据归约"></a>数据归约</h2><p>数据归约技术 Data Reduction可以用来得到数据集的归约表示，它小得多，但仍接近地保持原数据的完整性。</p>
<p>分为：</p>
<ul>
<li>维规约：降维</li>
<li>数量规约：用替代的、较小的的数据形式替换原始数据。比如只存放数据的模型参数</li>
<li>数据压缩：通过变换将原始数据压缩，不损失原来的信息叫做无损，否则是有损</li>
</ul>
<h3 id="维规约"><a href="#维规约" class="headerlink" title="维规约"></a>维规约</h3><h4 id="小波变换"><a href="#小波变换" class="headerlink" title="小波变换"></a>小波变换</h4><p>DWT）是一种线性信号处理技术，当用于数据向量D 时，将它转换成不同的数值向量小波系数D’。两个向量具有相同的长度。虽然变换后向量维度一样，但是可以仅存放一小部分最强的小波系数，就能保留近似的压缩数据。DWT提供比离散傅利叶DFT更好的有损压缩，DWT 将提供原数据更精确的近似。因此，对于等价的近似，DWT 比DFT 需要的空间小。不像DFT，小波空间局部性相当好，有助于保留局部细节。</p>
<p>该方法如下：</p>
<ol>
<li>输入数据向量的长度L 必须是2 的整数幂。必要时，通过在数据向量后添加0，这一条件可以满足。</li>
<li>每个变换涉及应用两个函数。第一个使用某种数据平滑，如求和或加权平均。第二个进行加权差分，产生数据的细节特征。</li>
<li>两个函数作用于输入数据对，产生两个长度为L/2 的数据集。一般地，它们分别代表输入数据的平滑后或低频的版本和它的高频内容。</li>
<li>两个函数递归地作用于前面循环得到的数据集，直到结果数据集的长度为2。</li>
<li>由以上迭代得到的数据集中选择值，指定其为数据变换的小波系数。</li>
</ol>
<h4 id="主成分分析"><a href="#主成分分析" class="headerlink" title="主成分分析"></a>主成分分析</h4><p>主成分分析PCA 又称Karhunen-Loeve 或K-L 方法）搜索c 个最能代表数据的k-维正交向量；这里c ≤ k。这样，原来的数据投影到一个较小的空间，导致数据压缩。PCA 可以作为一种维归约形式使用。然而，不象属性子集选择通过保留原属性集的一个子集来减少属性集的大小。PCA 通过创建一个替换的、较小的变量集“组合”属性的本质。原数据可以投影到该较小的集合中。</p>
<p>详解的过程暂时不记录，查看模式识别的教材。<strong>只适用数值数据</strong></p>
<h4 id="属性-特征子集选择"><a href="#属性-特征子集选择" class="headerlink" title="属性/特征子集选择"></a>属性/特征子集选择</h4><p>也就是降维。使用压缩搜索空间的启发式的算法，典型的是贪心算法。每次找到一个局部的好的属性，剔除掉差的属性。</p>
<p>属性子集选择的基本启发式方法包括以下技术：</p>
<ul>
<li>逐步向前选择：该过程由空属性集开始，选择原属性集中最好的属性，并将它添加到该集合中。</li>
<li>逐步向后删除：该过程由整个属性集开始。在每一步，删除掉尚在属性集中的最坏属性。</li>
<li>向前选择和向后删除的结合：向前选择和向后删除方法可以结合在一起，每一步选择一个最好的属性，并在剩余属性中删除一个最坏的属性。</li>
<li>判定树归纳：判定树算法，如ID3 和C4.5 。</li>
</ul>
<h3 id="数量规约"><a href="#数量规约" class="headerlink" title="数量规约"></a>数量规约</h3><h4 id="数据立方体集成"><a href="#数据立方体集成" class="headerlink" title="数据立方体集成"></a>数据立方体集成</h4><p>将数据整理成之前介绍过的数据立方体，把感兴趣的数据整理到基本立方体base cuboid上面。比如如果只关注每个季度的销售数据，那么可以将原来的每天的数据整理成每个季度的销售数据。这样就可以大大减少原来的数据量了。</p>
<h4 id="回归-1"><a href="#回归-1" class="headerlink" title="回归"></a>回归</h4><p>因为展开内容很多，只记录下有这些方法。当把数据拟合为某一种模型后只用记录这些模型的参数就可以了</p>
<ul>
<li>线性回归</li>
<li>多元线性回归</li>
<li>对数线性模型</li>
</ul>
<h4 id="直方图-1"><a href="#直方图-1" class="headerlink" title="直方图"></a>直方图</h4><p>就是前面叙述的分箱的方法，使用一个桶来记录一个属性的频次。或者等宽的方法，用区间来记录每个区间中的频次。</p>
<h4 id="聚类-1"><a href="#聚类-1" class="headerlink" title="聚类"></a>聚类</h4><p>聚类后，用数据的簇代表替换实际的数据。即只记录簇的中心点。</p>
<h4 id="抽样"><a href="#抽样" class="headerlink" title="抽样"></a>抽样</h4><p>假定大的数据集D 包含N 个元组。我们看看对D 的可能选样。</p>
<p>简单选择n 个样本，不回放(<strong>SRSWOR</strong>)：由D 的N 个元组中抽取n 个样本（n &lt; N）；其中， D中任何元组被抽取的概率均为1/N。即，所有元组是等可能的。</p>
<p>简单选择n 个样本，回放(<strong>SRSWR</strong>)：该方法类似于SRSWOR，不同在于当一个元组被抽取后，记录它，然后放回去。这样，一个元组被抽取后，它又被放回D，以便它可以再次被抽取。</p>
<h3 id="数据压缩"><a href="#数据压缩" class="headerlink" title="数据压缩"></a>数据压缩</h3><p>主要使用编码机制来进行压缩。包括字符串、音频、视频的压缩。</p>
<h3 id="数据离散和概念分层"><a href="#数据离散和概念分层" class="headerlink" title="数据离散和概念分层"></a>数据离散和概念分层</h3><p>可以使用分箱来、聚类、决策树和相关分析来进行离散化。而对于标称数据可以进行概念分层，前面的数据立方体就是用的这个思路。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>《数据挖掘概念与技术》第3版 第三章数据预处理</p>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">BraveY</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://bravey.github.io/2019-11-16-数据预处理.html">https://bravey.github.io/2019-11-16-数据预处理.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://bravey.github.io">BraveY</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/课程/">课程    </a><a class="post-meta__tags" href="/tags/国科大/">国科大    </a><a class="post-meta__tags" href="/tags/降维/">降维    </a><a class="post-meta__tags" href="/tags/相关性分析/">相关性分析    </a></div><div class="post_share"><div class="social-share" data-image="https://images.pexels.com/photos/1005763/pexels-photo-1005763.jpeg?auto=compress&amp;cs=tinysrgb&amp;dpr=1&amp;w=500" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><nav class="pagination_post" id="pagination"><div class="prev-post pull_left"><a href="/2019-11-17-分类与预测.html"><img class="prev_cover lazyload" data-src="https://images.pexels.com/photos/611328/pexels-photo-611328.jpeg?auto=compress&amp;cs=tinysrgb&amp;dpr=1&amp;w=500" onerror="onerror=null;src='/img/404.jpg'"><div class="label">上一篇</div><div class="prev_info"><span>分类与预测</span></div></a></div><div class="next-post pull_right"><a href="/2019-11-15-数据仓库.html"><img class="next_cover lazyload" data-src="https://images.pexels.com/photos/417222/pexels-photo-417222.jpeg?auto=compress&amp;cs=tinysrgb&amp;dpr=1&amp;w=500" onerror="onerror=null;src='/img/404.jpg'"><div class="label">下一篇</div><div class="next_info"><span>数据仓库</span></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fa fa-fw fa-thumbs-up" aria-hidden="true"></i><span> 相关推荐</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2019-11-15-数据仓库.html" title="数据仓库"><img class="relatedPosts_cover lazyload"data-src="https://images.pexels.com/photos/417222/pexels-photo-417222.jpeg?auto=compress&cs=tinysrgb&dpr=1&w=500"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2019-11-15</div><div class="relatedPosts_title">数据仓库</div></div></a></div><div class="relatedPosts_item"><a href="/2019-11-17-分类与预测.html" title="分类与预测"><img class="relatedPosts_cover lazyload"data-src="https://images.pexels.com/photos/611328/pexels-photo-611328.jpeg?auto=compress&cs=tinysrgb&dpr=1&w=500"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2019-11-17</div><div class="relatedPosts_title">分类与预测</div></div></a></div><div class="relatedPosts_item"><a href="/2019-11-19-聚类方法.html" title="聚类方法"><img class="relatedPosts_cover lazyload"data-src="https://images.pexels.com/photos/1562/italian-landscape-mountains-nature.jpg?auto=compress&cs=tinysrgb&dpr=1&w=500"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2019-11-19</div><div class="relatedPosts_title">聚类方法</div></div></a></div><div class="relatedPosts_item"><a href="/2019-11-18-关联规则.html" title="关联规则"><img class="relatedPosts_cover lazyload"data-src="https://images.pexels.com/photos/165505/pexels-photo-165505.jpeg?auto=compress&cs=tinysrgb&dpr=1&w=500"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2019-11-18</div><div class="relatedPosts_title">关联规则</div></div></a></div><div class="relatedPosts_item"><a href="/2019-11-19-推荐系统.html" title="推荐系统"><img class="relatedPosts_cover lazyload"data-src="https://images.pexels.com/photos/814499/pexels-photo-814499.jpeg?auto=compress&cs=tinysrgb&dpr=1&w=500"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2019-11-19</div><div class="relatedPosts_title">推荐系统</div></div></a></div><div class="relatedPosts_item"><a href="/2019-12-08-线性判别函数.html" title="线性判别函数"><img class="relatedPosts_cover lazyload"data-src="https://images.pexels.com/photos/1832328/pexels-photo-1832328.jpeg?auto=compress&cs=tinysrgb&dpr=1&w=500"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2019-12-08</div><div class="relatedPosts_title">线性判别函数</div></div></a></div></div><div class="clear_both"></div></div><hr><div id="post-comment"><div class="comment_headling"><i class="fa fa-comments fa-fw" aria-hidden="true"></i><span> 评论</span></div><div id="disqus_thread"></div><script>var unused = null;
var disqus_config = function () {
  this.page.url = 'https://bravey.github.io/2019-11-16-数据预处理.html';
  this.page.identifier = '2019-11-16-数据预处理.html';
  this.page.title = '数据预处理';
}
var d = document, s = d.createElement('script');
s.src = "https://" + 'bravey' +".disqus.com/embed.js";
s.setAttribute('data-timestamp', '' + +new Date());
(d.head || d.body).appendChild(s);</script></div></div></main><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2018 - 2020 By BraveY</div><div class="framework-info"><span>驱动 </span><a href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly"><span>Butterfly</span></a></div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="阅读模式"></i><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="简繁转换" target="_self">繁</a><i class="darkmode fa fa-moon-o" id="darkmode" title="夜间模式"></i></div><div id="rightside-config-show"><div id="rightside_config" title="设置"><i class="fa fa-cog" aria-hidden="true"></i></div><a id="to_comment" href="#post-comment" title="直达评论"><i class="scroll_to_comment fa fa-comments">  </i></a><i class="fa fa-list-ul close" id="mobile-toc-button" title="目录" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="回到顶部" aria-hidden="true"></i></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.jsdelivr.net/npm/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/js/fireworks.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@latest/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/lazysizes@latest/lazysizes.min.js" async=""></script><script src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/js/ClickShowText.js"></script><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a href="https://github.com/wzpan/hexo-generator-search" style="color:#49B1F5;">hexo-generator-search</a>
 <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>
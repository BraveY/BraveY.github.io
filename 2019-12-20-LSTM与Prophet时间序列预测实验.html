<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>LSTM与Prophet时间序列预测实验 | BraveY</title><meta name="description" content="LSTM与Prophet时间序列预测实验"><meta name="keywords" content="时间序列,LSTM,Pytorch,Prophet"><meta name="author" content="BraveY"><meta name="copyright" content="BraveY"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/favicon.png"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="https://fonts.googleapis.com" crossorigin="crossorigin"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="google-site-verification" content="hDujO4MQUB7U9ir-4VXM5PW4fDFSq0-7G-LBX-Lh86M"/><meta name="baidu-site-verification" content="8XIUcPkbzm"/><meta name="twitter:card" content="summary"><meta name="twitter:title" content="LSTM与Prophet时间序列预测实验"><meta name="twitter:description" content="LSTM与Prophet时间序列预测实验"><meta name="twitter:image" content="https://images.pexels.com/photos/71104/utah-mountain-biking-bike-biking-71104.jpeg?auto=compress&amp;cs=tinysrgb&amp;dpr=1&amp;w=500"><meta property="og:type" content="article"><meta property="og:title" content="LSTM与Prophet时间序列预测实验"><meta property="og:url" content="https://bravey.github.io/2019-12-20-LSTM%E4%B8%8EProphet%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E9%A2%84%E6%B5%8B%E5%AE%9E%E9%AA%8C.html"><meta property="og:site_name" content="BraveY"><meta property="og:description" content="LSTM与Prophet时间序列预测实验"><meta property="og:image" content="https://images.pexels.com/photos/71104/utah-mountain-biking-bike-biking-71104.jpeg?auto=compress&amp;cs=tinysrgb&amp;dpr=1&amp;w=500"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script>var autoChangeMode = '1'
var t = Cookies.get("theme")
if (autoChangeMode == '1'){
  var isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches
  var isLightMode = window.matchMedia("(prefers-color-scheme: light)").matches
  var isNotSpecified = window.matchMedia("(prefers-color-scheme: no-preference)").matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined){
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport){
      console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour < 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
  }
  } else if (t == 'light') activateLightMode()
  else activateDarkMode()

} else if (autoChangeMode == '2'){
  now = new Date();
  hour = now.getHours();
  isNight = hour < 6 || hour >= 18
  if(t === undefined) isNight? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode() 
} else {
  if ( t == 'dark' ) activateDarkMode()
  else if ( t == 'light') activateLightMode()
}

function activateDarkMode(){
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null){
    document.querySelector('meta[name="theme-color"]').setAttribute('content','#000')
  }
}
function activateLightMode(){
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null){
  document.querySelector('meta[name="theme-color"]').setAttribute('content','#fff')
  }
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="canonical" href="https://bravey.github.io/2019-12-20-LSTM%E4%B8%8EProphet%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E9%A2%84%E6%B5%8B%E5%AE%9E%E9%AA%8C.html"><link rel="prev" title="奇思妙想" href="https://bravey.github.io/2019-12-27-%E5%A5%87%E6%80%9D%E5%A6%99%E6%83%B3.html"><link rel="next" title="线性判别函数" href="https://bravey.github.io/2019-12-08-%E7%BA%BF%E6%80%A7%E5%88%A4%E5%88%AB%E5%87%BD%E6%95%B0.html"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容:${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://xxx/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: true,
  copyright: undefined,
  ClickShowText: {"text":"富强,民主,文明,和谐,自由,平等,公正,法治,爱国,敬业,诚信,友善","fontSize":"15px"},
  medium_zoom: false,
  fancybox: true,
  Snackbar: undefined,
  baiduPush: true,
  highlightCopy: true,
  highlightLang: true,
  highlightShrink: 'false',
  isFontAwesomeV5: false,
  isPhotoFigcaption: false
  
}</script><script>var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isSidebar: true  
  }</script><noscript><style>
#page-header {
  opacity: 1
}
.justified-gallery img{
  opacity: 1
}
</style></noscript><meta name="generator" content="Hexo 4.2.0"></head><body><canvas class="fireworks"></canvas><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/avatar3.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">63</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">94</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">14</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div></div></div></div><i class="fa fa-arrow-right on" id="toggle-sidebar" aria-hidden="true">     </i><div id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#LSTM与Prophet时间序列预测实验"><span class="toc-number">1.</span> <span class="toc-text">LSTM与Prophet时间序列预测实验</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#LSTM"><span class="toc-number">1.1.</span> <span class="toc-text">LSTM</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#数据预处理"><span class="toc-number">1.1.1.</span> <span class="toc-text">数据预处理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#LSTM网络构建"><span class="toc-number">1.1.2.</span> <span class="toc-text">LSTM网络构建</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#迭代"><span class="toc-number">1.1.3.</span> <span class="toc-text">迭代</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#测试过程"><span class="toc-number">1.1.4.</span> <span class="toc-text">测试过程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#GPU加速"><span class="toc-number">1.1.5.</span> <span class="toc-text">GPU加速</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Prophet"><span class="toc-number">1.2.</span> <span class="toc-text">Prophet</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Prophet的安装"><span class="toc-number">1.2.1.</span> <span class="toc-text">Prophet的安装</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#实验"><span class="toc-number">1.2.2.</span> <span class="toc-text">实验</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#总结"><span class="toc-number">1.3.</span> <span class="toc-text">总结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#参考"><span class="toc-number">1.4.</span> <span class="toc-text">参考</span></a></li></ol></li></ol></div></div></div><div id="body-wrap"><div id="web_bg" data-type="photo"></div><div class="post-bg" id="nav" style="background-image: url(https://images.pexels.com/photos/71104/utah-mountain-biking-bike-biking-71104.jpeg?auto=compress&amp;cs=tinysrgb&amp;dpr=1&amp;w=500)"><div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">BraveY</a></span><span class="pull_right menus"><div id="search_button"><a class="site-page social-icon search"><i class="fa fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div></div><span class="toggle-menu close"><a class="site-page"><i class="fa fa-bars fa-fw" aria-hidden="true"></i></a></span></span></div><div id="post-info"><div id="post-title"><div class="posttitle">LSTM与Prophet时间序列预测实验</div></div><div id="post-meta"><div class="meta-firstline"><time class="post-meta__date"><span class="post-meta__date-created" title="发表于 2019-12-20 22:24:26"><i class="fa fa-calendar" aria-hidden="true"></i> 发表于 2019-12-20</span><span class="post-meta__separator">|</span><span class="post-meta__date-updated" title="更新于 2020-04-25 16:17:58"><i class="fa fa-history" aria-hidden="true"></i> 更新于 2020-04-25</span></time><span class="post-meta__categories"><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span></div><div class="meta-secondline"> <span class="post-meta-wordcount"><i class="post-meta__icon fa fa-file-word-o" aria-hidden="true"></i><span>字数总计:</span><span class="word-count">2.3k</span><span class="post-meta__separator">|</span><i class="post-meta__icon fa fa-clock-o" aria-hidden="true"></i><span>阅读时长: 8 分钟</span></span></div><div class="meta-thirdline"><span class="post-meta-pv-cv"><span class="post-meta__separator">|</span><i class="fa fa-eye post-meta__icon" aria-hidden="true"> </i><span>阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-commentcount"><span class="post-meta__separator">|</span><i class="post-meta__icon fa fa-comment-o" aria-hidden="true"></i><span>评论数:</span><span class="disqus-comment-count comment-count"><a href="https://bravey.github.io/2019-12-20-LSTM%E4%B8%8EProphet%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E9%A2%84%E6%B5%8B%E5%AE%9E%E9%AA%8C.html#disqus_thread"></a></span></span></div></div></div></div><main class="layout_post" id="content-inner"><article id="post"><div id="article-container"><h1 id="LSTM与Prophet时间序列预测实验"><a href="#LSTM与Prophet时间序列预测实验" class="headerlink" title="LSTM与Prophet时间序列预测实验"></a>LSTM与Prophet时间序列预测实验</h1><p>分别使用Pytorch构建的LSTM网络与Facebook开源的Prophet工具对时间序列进行预测的一个对比小实验，同时作为一个小白也借着这个实验来学习下Pytorch的使用，因为第一次使用，所以会比较详细的注释代码。</p>
<a id="more"></a>
<p>使用的数据为了与Prophet进行对比，因此使用了Prophet官网例子上用到的数据集。该时间序列数据集来自维基百科上面对美国橄榄球运动员佩顿·曼宁（Peyton Williams Manning）的日访问量的记录日志，时间跨度为2007年12月10号到2016年1月20号共2905条数据。 </p>
<p>Jupyter代码与数据集地址在<a href="https://github.com/BraveY/AI-with-code/tree/master/time-series" target="_blank" rel="noopener">我的github</a>上，欢迎star。</p>
<h2 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h2><p>LSTM的介绍参考<a href="https://zhuanlan.zhihu.com/p/30465140" target="_blank" rel="noopener">夕小瑶</a>与<a href="https://zhuanlan.zhihu.com/p/32085405" target="_blank" rel="noopener">陈诚</a>的介绍，代码主要参考<a href="https://blog.csdn.net/baidu_36669549/article/details/85595807" target="_blank" rel="noopener">凌空的桨</a>与<a href="https://github.com/L1aoXingyu/code-of-learn-deep-learning-with-pytorch/tree/master/chapter5_RNN/time-series" target="_blank" rel="noopener">源码链接</a> ，在Pytorch1.3.1的版本上面改了一下，主要是测试的逻辑修改成了使用测试集以及取消了Variable的使用。整体的逻辑是使用前面的两天的数据来预测下一天的数据，网络的结构是使用了两层LSTM与一层线性回归层。</p>
<h3 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h3><p>首先是数据的预处理代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt </span><br><span class="line"><span class="keyword">import</span> torch </span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment">#数据预处理</span></span><br><span class="line">data = pd.read_csv(<span class="string">'example_wp_log_peyton_manning.csv'</span>,usecols=[<span class="number">1</span>])</span><br><span class="line">data = data.dropna() <span class="comment">#丢弃空值</span></span><br><span class="line">dataset = data.values</span><br><span class="line">dataset = dataset.astype(<span class="string">'float32'</span>)</span><br><span class="line"></span><br><span class="line">max_value = np.max(dataset)</span><br><span class="line">min_value = np.min(dataset)</span><br><span class="line">scalar = max_value - min_value</span><br><span class="line">dataset = list(map(<span class="keyword">lambda</span> x: x/scalar, dataset)) <span class="comment">#将数据归一化到0~1之间</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#划分数据集</span></span><br><span class="line"><span class="comment">#通过前面几条的数据来预测下一条的数据，look_back设置具体的把前面几条的数据作为预测的输入data_X，而输出就是下一条data_Y</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_dataset</span><span class="params">(dataset,look_back=<span class="number">2</span>)</span>:</span> <span class="comment"># 每个的滑动窗口设置为2</span></span><br><span class="line">    dataX, dataY=[], []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(dataset)-look_back):</span><br><span class="line">        a=dataset[i:(i+look_back)]</span><br><span class="line">        dataX.append(a)    <span class="comment"># 记录窗口的值</span></span><br><span class="line">        dataY.append(dataset[i+look_back]) <span class="comment"># 记录除了前面两个以外的所有值作为正确的标签</span></span><br><span class="line">    <span class="keyword">return</span> np.array(dataX), np.array(dataY)</span><br><span class="line"><span class="comment">#创建好输入与输出 data_Y作为正确的预测值</span></span><br><span class="line">data_X, data_Y = create_dataset(dataset)</span><br><span class="line"></span><br><span class="line"><span class="comment">#划分训练集和测试集，70%作为训练集</span></span><br><span class="line">train_size = int(len(data_X) * <span class="number">0.7</span>)</span><br><span class="line">test_size = len(data_X)-train_size</span><br><span class="line"></span><br><span class="line">train_X = data_X[:train_size]</span><br><span class="line">train_Y = data_Y[:train_size]</span><br><span class="line"></span><br><span class="line">test_X = data_X[train_size:]</span><br><span class="line">test_Y = data_Y[train_size:]</span><br><span class="line"></span><br><span class="line"><span class="comment">#最后，我们需要将数据改变一下形状，因为 RNN 读入的数据维度是 (seq, batch, feature)，所以要重新改变一下数据的维度，这里只有一个序列，所以 batch 是 1，而输入的 feature 就是我们希望依据的几天，这里我们定的是两个天，所以 feature 就是 2.</span></span><br><span class="line"></span><br><span class="line">train_X = train_X.reshape(<span class="number">-1</span>,<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line">train_Y = train_Y.reshape(<span class="number">-1</span>,<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">test_X = test_X.reshape(<span class="number">-1</span>,<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 转化成torch 的张量</span></span><br><span class="line">train_x = torch.from_numpy(train_X)</span><br><span class="line">train_y = torch.from_numpy(train_Y)</span><br><span class="line">test_x = torch.from_numpy(test_X)</span><br></pre></td></tr></table></figure>
<h3 id="LSTM网络构建"><a href="#LSTM网络构建" class="headerlink" title="LSTM网络构建"></a>LSTM网络构建</h3><p>接着定义好网络模型，模型的第一部分是一个两层的 RNN，每一步模型接受前两天的输入作为特征，得到一个输出特征。接着通过一个线性层将 RNN 的输出回归到流量的具体数值，这里我们需要用 <code>view</code> 来重新排列，因为 <code>nn.Linear</code> 不接受三维的输入，所以我们先将前两维合并在一起，然后经过线性层之后再将其分开，最后输出结果。 </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#lstm 网络</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">lstm_reg</span><span class="params">(nn.Module)</span>:</span><span class="comment">#括号中的是python的类继承语法，父类是nn.Module类 不是参数的意思</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,input_size,hidden_size, output_size=<span class="number">1</span>,num_layers=<span class="number">2</span>)</span>:</span> <span class="comment"># 构造函数</span></span><br><span class="line">        <span class="comment">#inpu_size 是输入的样本的特征维度， hidden_size 是LSTM层的神经元个数，</span></span><br><span class="line">        <span class="comment">#output_size是输出的特征维度</span></span><br><span class="line">        super(lstm_reg,self).__init__()<span class="comment"># super用于多层继承使用，必须要有的操作</span></span><br><span class="line"> </span><br><span class="line">        self.rnn = nn.LSTM(input_size,hidden_size,num_layers)<span class="comment"># 两层LSTM网络，</span></span><br><span class="line">        self.reg = nn.Linear(hidden_size,output_size)<span class="comment">#把上一层总共hidden_size个的神经元的输出向量作为输入向量，然后回归到output_size维度的输出向量中</span></span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,x)</span>:</span> <span class="comment">#x是输入的数据</span></span><br><span class="line">        x, _ = self.rnn(x)<span class="comment"># 单个下划线表示不在意的变量，这里是LSTM网络输出的两个隐藏层状态</span></span><br><span class="line">        s,b,h = x.shape</span><br><span class="line">        x = x.view(s*b, h)</span><br><span class="line">        x = self.reg(x)</span><br><span class="line">        x = x.view(s,b,<span class="number">-1</span>)<span class="comment">#使用-1表示第三个维度自动根据原来的shape 和已经定了的s,b来确定</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"><span class="comment">#我使用了GPU加速，如果不用的话需要把.cuda()给注释掉    </span></span><br><span class="line">net = lstm_reg(<span class="number">2</span>,<span class="number">4</span>)</span><br><span class="line">net = net.cuda()</span><br><span class="line">criterion = nn.MSELoss().cuda()</span><br><span class="line">optimizer = torch.optim.Adam(net.parameters(),lr=<span class="number">1e-2</span>)</span><br></pre></td></tr></table></figure>
<p>本来打算把网络拓扑也给画出来的，后面发现自己理解的还不够深入，可以先参考<a href="https://www.zhihu.com/question/41949741/answer/318771336" target="_blank" rel="noopener">LSTM神经网络输入输出究竟是怎样的？ - Scofield的回答 - 知乎 </a> 和<a href="https://zhuanlan.zhihu.com/p/79064602" target="_blank" rel="noopener">LSTM细节分析理解（pytorch版） - ymmy的文章 - 知乎 </a></p>
<p>关于forward函数中为什么每个层可以直接使用输入的数据x这个tensor，而不需要按照构造函数里面的按照形参(input_size,hidden_size,num_layers)来传递参数。以nn.LSTM做例子，官方API为：</p>
<ul>
<li>参数<br>– <strong>input_size</strong><br>– <strong>hidden_size</strong><br>– <strong>num_layers</strong><br>– <strong>bias</strong><br>– <strong>batch_first</strong><br>– <strong>dropout</strong><br>– <strong>bidirectional</strong></li>
<li>输入<br>– <strong>input</strong> (seq_len, batch, input_size)<br>– <strong>h_0</strong> (num_layers <em> num_directions, batch, hidden_size)<br>– <strong>c_0</strong> (num_layers </em> num_directions, batch, hidden_size)</li>
<li><p>输出<br>– <strong>output</strong> (seq_len, batch, num_directions <em> hidden_size)<br>– <strong>h_n</strong> (num_layers </em> num_directions, batch, hidden_size)<br>– <strong>c_n</strong> (num_layers * num_directions, batch, hidden_size)</p>
<p>所以forward中的x，<code>x, _ = self.rnn(x)</code>传递的参数是对应输入<strong>input</strong> (seq_len, batch, input_size)这个tensor，而不是对应的参数列表。同样<code>_</code>所代表的参数也就是<strong>h_n</strong> 和<strong>c_n</strong>。</p>
</li>
</ul>
<h3 id="迭代"><a href="#迭代" class="headerlink" title="迭代"></a>迭代</h3><p>迭代过程进行了10000次迭代：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> e <span class="keyword">in</span> range(<span class="number">10000</span>):</span><br><span class="line"><span class="comment"># 新版本中可以不使用Variable了    </span></span><br><span class="line"><span class="comment">#     var_x = Variable(train_x).cuda() </span></span><br><span class="line"><span class="comment">#     var_y = Variable(train_y).cuda()</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#将tensor放在GPU上面进行运算</span></span><br><span class="line">    var_x = train_x.cuda()</span><br><span class="line">    var_y = train_y.cuda()</span><br><span class="line"> </span><br><span class="line">    out = net(var_x)</span><br><span class="line">    loss = criterion(out, var_y)</span><br><span class="line"> </span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line">    <span class="keyword">if</span> (e+<span class="number">1</span>)%<span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">        print(<span class="string">'Epoch: &#123;&#125;, Loss:&#123;:.5f&#125;'</span>.format(e+<span class="number">1</span>, loss.item()))</span><br><span class="line"><span class="comment">#存储训练好的模型参数        </span></span><br><span class="line">torch.save(net.state_dict(), <span class="string">'example_wp_log.net_params.pkl'</span>)</span><br></pre></td></tr></table></figure>
<h3 id="测试过程"><a href="#测试过程" class="headerlink" title="测试过程"></a>测试过程</h3><p>在测试的时候我发现源码中并没有用到之前划分的30%的测试集来单独进行测试，而是直接把原来的完整数据给丢进去来训练的，这儿有点没搞懂。因为按理来说需要单独使用测试集进行测试来评判模型的性能的，所以我单独把测试的数据集给提出来，使用单独的测试集进行了测试。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">net.load_state_dict(torch.load(<span class="string">'example_wp_log.net_params.pkl'</span>)) </span><br><span class="line">var_data = torch.from_numpy(test_X).cuda()<span class="comment">#net在GPU上面，所以输入的测试集合也要转入到GPU上面</span></span><br><span class="line">pred_test = net(var_data) <span class="comment"># 测试集的预测结果</span></span><br><span class="line">pred_test = pred_test.cpu().view(<span class="number">-1</span>).data.numpy()<span class="comment">#先转移到cpu上才能转换为numpy</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#乘以原来归一化的刻度放缩回到原来的值域 </span></span><br><span class="line">origin_test_Y = test_Y*scalar</span><br><span class="line">origin_pred_test = pred_test*scalar</span><br><span class="line"></span><br><span class="line"><span class="comment">#画图</span></span><br><span class="line">plt.plot(origin_pred_test, <span class="string">'r'</span>, label=<span class="string">'prediction'</span>)</span><br><span class="line">plt.plot(origin_test_Y, <span class="string">'b'</span>, label=<span class="string">'real'</span>)</span><br><span class="line">plt.legend(loc=<span class="string">'best'</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment">#计算MSE</span></span><br><span class="line"><span class="comment">#loss = criterion(out, var_y)？</span></span><br><span class="line">true_data = origin_test_Y</span><br><span class="line">true_data = np.array(true_data)</span><br><span class="line">true_data = np.squeeze(true_data)  <span class="comment"># 从二维变成一维</span></span><br><span class="line">MSE = true_data - origin_pred_test</span><br><span class="line">MSE = MSE*MSE</span><br><span class="line">MSE_loss = sum(MSE)/len(MSE)</span><br><span class="line">print(MSE_loss)</span><br></pre></td></tr></table></figure>
<p>计算出来的MSE为<code>0.195649022176008</code>, 画出来的曲线图为：</p>
<p><img src="/" class="lazyload" data-src="https://res.cloudinary.com/bravey/image/upload/v1576911405/blog/deep-learning/LSTM_time_series.png"  alt=""></p>
<h3 id="GPU加速"><a href="#GPU加速" class="headerlink" title="GPU加速"></a>GPU加速</h3><p><code>use_gpu = torch.cuda.is_available()  # 判断是否有GPU加速</code></p>
<p>CUDA 加速需要设置的为：</p>
<ol>
<li>迭代的过程中输入的tensor放到GPU上  var_x = train_x.cuda()</li>
<li>模型转移到GPU net.cuda()</li>
<li>损失函数转移到GPU criterion = nn.MSELoss().cuda()</li>
</ol>
<h2 id="Prophet"><a href="#Prophet" class="headerlink" title="Prophet"></a>Prophet</h2><p>Prophet是facebook开源的一个时间序列预测工具,使用了时间序列分解与机器学习拟合的方法。详细介绍参考<a href="https://zhuanlan.zhihu.com/p/52330017" target="_blank" rel="noopener">张戎</a>的介绍。</p>
<h3 id="Prophet的安装"><a href="#Prophet的安装" class="headerlink" title="Prophet的安装"></a>Prophet的安装</h3><p>在安装Prophet的时候并没有想官网介绍的那么简单，首先需要先安装Pystan,但是直接<code>pip install pystan</code>会报编译器内部错误，使用<code>conda install -c conda-forge pystan</code>之后问题解决，然后再使用<code>pip install fbprophet</code> 进行安装。</p>
<h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><p>实验的例子就是官网的例子</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> fbprophet <span class="keyword">import</span> Prophet</span><br><span class="line">df = pd.read_csv(<span class="string">'example_wp_log_peyton_manning.csv'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#Prophet使用</span></span><br><span class="line">m = Prophet()</span><br><span class="line">m.fit(df)</span><br><span class="line"><span class="comment">#需要预测时间段为整个365天，也就是下一年的整个天数</span></span><br><span class="line">future = m.make_future_dataframe(periods=<span class="number">365</span>)</span><br><span class="line"><span class="comment">#开始预测</span></span><br><span class="line">forecast = m.predict(future)</span><br><span class="line"><span class="comment">#预测的结果保存在yhat_upper列中</span></span><br><span class="line">forecast[[<span class="string">'ds'</span>, <span class="string">'yhat'</span>, <span class="string">'yhat_lower'</span>, <span class="string">'yhat_upper'</span>]].tail()</span><br><span class="line"><span class="comment">#画图</span></span><br><span class="line">plt.plot(fb_pre, <span class="string">'r'</span>, label=<span class="string">'prediction'</span>)</span><br><span class="line">plt.plot(origin_test_Y, <span class="string">'b'</span>, label=<span class="string">'real'</span>)</span><br><span class="line">plt.legend(loc=<span class="string">'best'</span>)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment">#计算MSE</span></span><br><span class="line">fb_pre = np.array(forecast[<span class="string">'yhat'</span>].iloc[<span class="number">2034</span>:<span class="number">2905</span>])<span class="comment">#2034到2905是前面30%的测试集所对应的数据范围</span></span><br><span class="line">MSE = true_data - fb_pre</span><br><span class="line">MSE = MSE*MSE</span><br><span class="line">MSE_loss = sum(MSE)/len(MSE)</span><br><span class="line">print(MSE_loss)</span><br></pre></td></tr></table></figure>
<p>计算出来的MSE为：<code>0.25229994660830146</code>,画出来的图像为：</p>
<p><img src="/" class="lazyload" data-src="https://res.cloudinary.com/bravey/image/upload/v1576911405/blog/deep-learning/Prophet_time_series.png"  alt=""></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><div class="table-container">
<table>
<thead>
<tr>
<th>方法</th>
<th>MSE</th>
</tr>
</thead>
<tbody>
<tr>
<td>LSTM</td>
<td>0.195649022176008</td>
</tr>
<tr>
<td>Prophet</td>
<td>0.25229994660830146</td>
</tr>
</tbody>
</table>
</div>
<p>可以看到使用LSTM的预测结果要比Prophet的结果好，但是也有可能是我还没有去调整Prophet的参数导致Prophet的性能差一些的。同时Prophet可以预测整整一年的时间，这个比起使用LSTM要厉害很多，实验中的LSTM使用的是单步预测的方法，也就是只能根据前段时刻的数据来预测下一个时刻的数据，如果要做到像Prophet那样预测未来一段时刻的数据，需要使用多步预测的方法，我查了下涉及到seq2seq，貌似比较复杂，还没有做实验。</p>
<p>自己是小白，实验可能存在相关问题与不足之处，欢迎反馈。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>Pytorch中的<a href="https://zhuanlan.zhihu.com/p/41261640" target="_blank" rel="noopener">LSTM参数</a></p>
<p><a href="https://facebook.github.io/prophet/" target="_blank" rel="noopener">Prophet官网</a></p>
<p><a href="https://www.okcode.net/article/43571" target="_blank" rel="noopener">Prophet安装问题</a> </p>
</div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">BraveY</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://bravey.github.io/2019-12-20-LSTM%E4%B8%8EProphet%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E9%A2%84%E6%B5%8B%E5%AE%9E%E9%AA%8C.html">https://bravey.github.io/2019-12-20-LSTM%E4%B8%8EProphet%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E9%A2%84%E6%B5%8B%E5%AE%9E%E9%AA%8C.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://bravey.github.io" target="_blank">BraveY</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97/">时间序列</a><a class="post-meta__tags" href="/tags/LSTM/">LSTM</a><a class="post-meta__tags" href="/tags/Pytorch/">Pytorch</a><a class="post-meta__tags" href="/tags/Prophet/">Prophet</a></div><div class="post_share"><div class="social-share" data-image="https://images.pexels.com/photos/71104/utah-mountain-biking-bike-biking-71104.jpeg?auto=compress&amp;cs=tinysrgb&amp;dpr=1&amp;w=500" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"/><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><nav class="pagination_post" id="pagination"><div class="prev-post pull_left"><a href="/2019-12-27-%E5%A5%87%E6%80%9D%E5%A6%99%E6%83%B3.html"><img class="prev_cover lazyload" data-src="https://images.pexels.com/photos/33545/sunrise-phu-quoc-island-ocean.jpg?auto=compress&amp;cs=tinysrgb&amp;dpr=1&amp;w=500" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">奇思妙想</div></div></a></div><div class="next-post pull_right"><a href="/2019-12-08-%E7%BA%BF%E6%80%A7%E5%88%A4%E5%88%AB%E5%87%BD%E6%95%B0.html"><img class="next_cover lazyload" data-src="https://images.pexels.com/photos/46253/mt-fuji-sea-of-clouds-sunrise-46253.jpeg?auto=compress&amp;cs=tinysrgb&amp;dpr=1&amp;w=500" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">线性判别函数</div></div></a></div></nav><hr><div id="post-comment"><div class="comment_headling"><i class="fa fa-comments fa-fw" aria-hidden="true"></i><span> 评论</span></div><div id="disqus_thread"></div><script>var disqus_config = function () {
  this.page.url = 'https://bravey.github.io/2019-12-20-LSTM%E4%B8%8EProphet%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E9%A2%84%E6%B5%8B%E5%AE%9E%E9%AA%8C.html';
  this.page.identifier = '2019-12-20-LSTM与Prophet时间序列预测实验.html';
  this.page.title = 'LSTM与Prophet时间序列预测实验';
};
(function() { 
  var d = document, s = d.createElement('script');
  s.src = 'https://bravey.disqus.com/embed.js';
  s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
})();
</script><script>function getDisqusCount() {
  var d = document, s = d.createElement('script');
  s.src = 'https://bravey.disqus.com/count.js';
  s.id = 'dsq-count-scr';
  (d.head || d.body).appendChild(s);
}

window.addEventListener('load', getDisqusCount, false);</script></div></article></main><footer id="footer" style="background-image: url(https://images.pexels.com/photos/71104/utah-mountain-biking-bike-biking-71104.jpeg?auto=compress&amp;cs=tinysrgb&amp;dpr=1&amp;w=500)" data-type="photo"><div id="footer-wrap"><div class="copyright">&copy;2018 - 2020 By BraveY</div><div class="framework-info"><span>驱动 </span><a href="https://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="阅读模式"></i><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="简繁转换" target="_self">繁</a><i class="darkmode fa fa-moon-o" id="darkmode" title="夜间模式"></i></div><div id="rightside-config-show"><div id="rightside_config" title="设置"><i class="fa fa-cog" aria-hidden="true"></i></div><a id="to_comment" href="#post-comment" title="直达评论"><i class="scroll_to_comment fa fa-comments">  </i></a><i class="fa fa-list-ul close" id="mobile-toc-button" title="目录" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="回到顶部" aria-hidden="true"></i></div></section><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a href="https://github.com/wzpan/hexo-generator-search" target="_blank" rel="noopener" style="color:#49B1F5;">hexo-generator-search</a>
 <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.jsdelivr.net/npm/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="/js/third-party/fireworks.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@latest/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/lazysizes@latest/lazysizes.min.js" async=""></script><script src="/js/third-party/ClickShowText.js"></script><script src="/js/search/local-search.js"></script></body></html>